Title: Day 19: AI as Code Reviewer
Day: 19
Date: Jan 19, 2026
Characters: 5904
Words: 909
==================================================

Welcome to Day 19 of 31 Days of Vibe Coding. Today's topic is: AI as Code Reviewer.

Code review is a single pass.

Someone looks at your code, leaves comments, you address them, done. One perspective, one set of concerns, one opportunity to catch problems.

The problem with single-pass review: different people catch different things. The security expert sees vulnerabilities. The performance person sees bottlenecks. The maintainability person sees code smells. One reviewer can’t hold all these lenses simultaneously.

AI can do multiple passes. Each pass with a different focus. Security pass, then performance pass, then maintainability pass, then edge cases. Four perspectives instead of one. More issues caught before production.

The Multi-Pass System

Here’s how I structure AI code reviews:

Pass 1: Security Does this code create vulnerabilities?

Pass 2: Performance Will this code be fast enough at scale?

Pass 3: Maintainability Will future developers understand this code?

Pass 4: Edge Cases What inputs will break this code?

Each pass has a specific prompt. Each finds different issues. Together, they’re more thorough than any single review.

Pass 1: Security Review

Showing a prompt template that instructs an AI to perform a security code review, checking for common vulnerabilities like injection attacks and authentication issues, and requesting structured findings with severity ratings and fixes.

Pass 2: Performance Review

Showing a prompt template that instructs an AI to act as a performance engineer reviewing code for common efficiency issues like N+1 queries, missing pagination, and algorithm complexity.

Pass 3: Maintainability Review

Showing a prompt template that instructs an AI to perform a code review checking for maintainability issues like clarity, naming, structure, and duplication.

Pass 4: Edge Case Review

Showing a prompt template that instructs an AI to act as a QA engineer and systematically find edge cases that could break provided code.

Consolidating Feedback

After four passes, you have a lot of feedback. Consolidate it:

Showing a prompt template that asks an AI to consolidate feedback from four code review passes into a prioritized list grouped by severity level.

A Real Multi-Pass Review

Here’s code AI generated for user registration:

Showing an Express route handler for user registration that checks for existing emails, hashes the password with bcrypt, creates the user in the database, and returns a JWT token.

Security pass found:

Email existence exposed (timing attack + information disclosure)

No password strength validation

JWT token never expires

Full user object returned (might include sensitive fields)

No rate limiting (brute force registration)

Performance pass found:

No issues at this scale

Maintainability pass found:

Magic number 10 for bcrypt rounds should be constant

No input validation before database operation

Error handling doesn’t log for observability

Edge case pass found:

No validation on email format

No validation on name (empty string accepted)

Very long strings accepted (no length limits)

Password can be empty string

Consolidated and prioritized:

Critical:

Add rate limiting to prevent abuse

Add JWT expiration

Don’t reveal if email exists

High:

Validate password strength

Validate email format

Limit returned user fields

Medium:

Extract bcrypt rounds to constant

Add input length limits

Add observability logging

Low:

Add name validation

One review pass might catch 3-4 of these. Four passes caught 12.

Review by Persona

Sometimes you want specific expertise:

Showing a prompt template that asks an AI to review code from three different perspectives: a junior developer, an on-call engineer, and a future maintainer, listing concerns for each.

The Pre-Commit Review

Quick review before committing:

Showing a prompt template for quick code review that asks an AI to check a diff for bugs, security issues, performance problems, and embarrassing code.

The PR Description Generator

AI can also write your PR description based on code review:

Showing a prompt template that instructs an AI to generate a pull request description from a code diff, covering summary, rationale, approach, testing, risks, and rollback steps.

When AI Review Falls Short

AI reviews aren’t perfect:

Business logic: AI doesn’t know your business rules. It can’t tell if the logic is correct for your domain.

Context: AI doesn’t know why you made certain decisions. It might flag something as wrong that’s intentionally that way.

Style debates: AI will have opinions about formatting, naming, structure. Not all of them match your team’s style.

False positives: AI sometimes flags things that aren’t actually problems.

Use AI review as a first pass, not the only pass. It catches the obvious stuff so human reviewers can focus on business logic and context.

Building Review Into Your Workflow

Don’t save review for the end. Review as you go:

Showing a workflow checklist for code review stages, from pre-implementation planning through PR submission and human review.

AI review is cheap. Run it often.

The Review Checklist

Before any code goes to PR:

Showing a checklist for tracking completion of code review passes covering security, performance, maintainability, edge cases, and issue resolution.

Tomorrow

Code reviewed. Tests written. But there’s a bug. Where is it?

Tomorrow I’ll show you how to use AI as a debugger. Systematic bug hunting that narrows down the problem faster than printf debugging.

Try This Today

Take a piece of code you’re about to commit

Run the security pass

Run the edge case pass

See what you missed

Two passes will likely find something one pass missed. That’s the point. More lenses, more coverage, fewer bugs in production.

That's it for Day 19. Join us tomorrow for Day 20. Thanks for listening to 31 Days of Vibe Coding.
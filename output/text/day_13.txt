Title: Day 13: Stop AI From Changing What You Didn't Ask For
Day: 13
Date: Jan 13, 2026
Characters: 6498
Words: 1102
==================================================

Welcome to Day 13 of 31 Days of Vibe Coding. Today's topic is: Stop AI From Changing What You Didn't Ask For.

I needed to change an error message.

One line. The error said “Invalid user” and I wanted it to say “User not found or inactive.” A five-word change.

Claude changed the error message. Great.

Claude also renamed the function from validateUser to checkUserStatus because the new behavior was “more accurately described.” It refactored the validation logic “for clarity.” It updated three other files that referenced the old function name.

I asked for five words. I got a mini-refactor across four files.

This happens constantly. AI sees opportunities to “improve” and takes them, even when you didn’t ask. The improvements might even be good ideas. But they’re not what you asked for, they’re not what you tested, and they might break things you weren’t thinking about.

AI needs boundaries. Here’s how to set them.

Why AI Over-Helps

AI is trained to be helpful. Really helpful. When it sees code that could be “better,” it wants to fix it. When it sees inconsistent naming, it wants to clean it up. When it sees an opportunity to improve, it takes it.

This comes from good intentions. But in a real codebase, unsolicited changes are dangerous:

They’re not tested

They’re not reviewed

They might break things

They’re not in scope

They confuse git history

They make code review harder

You need AI to do exactly what you ask. No more.

The Magic Phrase

The single most effective constraint I’ve found:

A code example with 2 lines - see the article for details.

That’s it. Those two sentences dramatically reduce scope creep.

Put them at the end of any surgical request:

A code example with 4 lines - see the article for details.

AI will make that one change. Nothing more.

Constraining By File

When you want changes limited to specific files:

A code example with 5 lines - see the article for details.

This prevents the “helpful” cascade where AI fixes one file and then “updates” the files that reference it.

Constraining By Function

For changes within a file:

A code example with 5 lines - see the article for details.

AI stays focused on one function.

Constraining By Line

For surgical precision:

A code example with 3 lines - see the article for details.

Sometimes you need this level of precision. AI can handle it.

The “Ask First” Pattern

When you’re not sure about scope, make AI ask:

A code example with 8 lines - see the article for details.

Now you see the scope before it happens. You can say “yes to 1 and 2, no to 3.”

The “Show Don’t Apply” Pattern

For risky changes:

A code example with 4 lines - see the article for details.

Review the proposed changes. If they’re right:

A code example with 1 lines - see the article for details.

If they include unwanted extras:

A code example with 1 lines - see the article for details.

Explicit Scopes

Be explicit about what’s in and out of scope:

A code example with 12 lines - see the article for details.

The out-of-scope list is as important as the in-scope list. It tells AI where the boundaries are.

When AI Says It Needs More Changes

Sometimes AI will push back:

“I notice that adding pagination would also require updating the response type. Should I do that?”

This is AI asking permission. Good.

Answer specifically:

A code example with 2 lines - see the article for details.

Or:

A code example with 1 lines - see the article for details.

Don’t just say “sure” to everything AI suggests. Each expansion of scope is a choice.

Red Flags to Watch For

Review AI’s changes for unsolicited modifications:

Renamed variables or functions. You didn’t ask for renaming. Why did it happen?

“Cleaned up” code. Did AI simplify something you didn’t ask about?

Modified other files. You asked for changes to file A. Why did files B, C, D change?

Added features. You asked for X. Why is there also Y?

Changed formatting. Did AI reformat code it didn’t need to touch?

When you see these, either:

Roll back and re-request with tighter constraints

Accept this change but note the pattern for next time

Using Git to Verify Scope

After AI makes changes, always check:

A code example with 1 lines - see the article for details.

This shows which files changed and how much. If you asked for a one-line change and see 10 files modified, something went wrong.

A code example with 1 lines - see the article for details.

This shows exactly what changed. Look for:

Changes outside your requested scope

Renamed identifiers

Reformatted code

Additional features

If you see unexpected changes:

A code example with 1 lines - see the article for details.

Start over with tighter constraints.

Template for Surgical Changes

A code example with 15 lines - see the article for details.

Example:

A code example with 15 lines - see the article for details.

When Broad Changes Are Okay

Not every change needs tight constraints. Broad AI assistance works for:

New features (AI can design the structure)

Initial implementations (no existing code to break)

Exploratory work (you’ll review everything anyway)

Refactoring tasks (where broad changes are the point)

Use tight constraints for:

Bug fixes in existing code

Small changes to working systems

Changes near complex logic

Anything in production-critical paths

The Balance

There’s a tension here. Too tight and you’re micromanaging. Too loose and you’re cleaning up surprises.

My rule: the more important the existing code, the tighter the constraints.

For a throwaway script, let AI do whatever. For the payment processing service, constrain every line.

Tomorrow

You’ve learned to constrain AI’s changes. But sometimes AI goes beyond unwanted changes. It starts hallucinating. Generating functions that don’t exist. Referencing APIs that aren’t real. Confidently producing nonsense.

Tomorrow I’ll show you how to spot hallucination and stop it before it breaks your code.

Try This Today

Next time you ask AI for a small change:

Add “Make this exact change and NOTHING else”

Run git diff --stat after to see what changed

Note if AI stayed in scope or drifted

If it drifted, refine your constraints and try again

Build the habit of explicit constraints. It takes a few extra words but saves significant review and rollback time.

AI wants to help. Your job is to define exactly what “help” means for each request.

That's it for Day 13. Join us tomorrow for Day 14. Thanks for listening to 31 Days of Vibe Coding.